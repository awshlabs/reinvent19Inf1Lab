# Reinvent Inf1 Lab: Hands-on Deep Learning Inference with Amazon EC2 Inf1 Instance

## Abstract:

In this workshop, you gain hands-on experience with Amazon EC2 Inf1 instances, powered by custom AWS Inferentia chips. Amazon EC2 Inf1 instances offer low-latency, high-throughput, and cost-effective machine learning inference in the cloud. This workshop walks you through taking a trained deep learning model to deployment on Amazon EC2 Inf1 instances by using AWS Neuron, an SDK for optimizing inference using AWS Inferentia processors.


## Overview:

1. **Launch** a C5 Instance, **install** the Neuron development environment, Custom compile a pre-trained model to target the Inferentia Neuron Processor.   
2. **Launch** an Inf1 Instance, **install** Neuron run-time and development environment, **test** and **model serve** the compiled ResNet package.   
3. **Compile and Launch** a loadtest run on Inferentia Instance.   
4. **Debug and Profile** your model. 

