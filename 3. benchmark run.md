# Lab 3: Compile and Launch a load test run on Inf1 Instance.

**Please complete Lab 2 and clean up by following Lab 2's last step. If using DLAMI Conda environment, please update to [latest Neuron software](https://github.com/aws/aws-neuron-sdk/blob/master/release-notes/dlami-release-notes.md) for this lab.**

This lab shows an example load testing using FP16 model derived from Keras ResNet50 model and compiled to Inferentia with experimental performance flags. For this lab please use inf1.2xlarge and update to latest Neuron software.

**3.1** Download and unpack the ResNet50 performance package on Inf1 instance:

```bash
wget https://reinventinf1.s3.amazonaws.com/keras_fp16_benchmarking_db.tgz
```
```bash
tar -xzf keras_fp16_benchmarking_db.tgz
```
```bash
cd keras_fp16_benchmarking_db
```

**3.2** Activate virtual environment and install Neuron Compiler if not done so. Also install pillow module for test scripts.

```bash
source test_env_p36/bin/activate
pip install neuron-cc
pip install pillow
```

**3.3** Extract Keras ResNet50 FP32, optimize for inference, and convert to FP16.

Extract Keras ResNet50 FP32 (resnet50_fp32_keras.pb will be generated):

```bash
python gen_resnet50_keras.py
```
Optimize the extracted Keras ResNet50 FP32 graph for inference before casting (resnet50_fp32_keras_opt.pb will be generated):

```bash
python optimize_for_inference.py --graph resnet50_fp32_keras.pb --out_graph resnet50_fp32_keras_opt.pb
```

Convert full graph to FP16 (resnet50_fp16_keras_opt.pb will be generated):
```bash
python fp32tofp16.py  --graph resnet50_fp32_keras_opt.pb --out_graph resnet50_fp16_keras_opt.pb
```

**3.4** Compile ResNet50 frozen graph using provided pb2sm_compile.py script on Inf1 instance. This step takes about 4 minutes on Inf1.2xlarge.
>We optimized this model with a compiled time batch size of 5. We optimize throughput having a runtime batch size of mutiples of 5. (50 in this case). This step takes about 6 minutes.

```bash
time python pb2sm_compile.py
```

NOTE: please ensure that the Neuron Compiler is up-to-date.

**3.5** Run load test using provided infer_resnet50_keras_loadtest.py script on Inf1 instance (please make sure this is inf1.2xlarge):

> There are total of 4 Neuron Cores on Inf1.2xlarge.  There are 4 sessions of ResNet50 running, each session binds to a Neuron core. There are 4 threads in each of these sessions.  

```bash
time python infer_resnet50_keras_loadtest.py
```
Output:

```
NUM THREADS:  16
NUM_LOOPS_PER_THREAD:  100
USER_BATCH_SIZE:  50
current throughput: 0 images/sec
current throughput: 0 images/sec
current throughput: 300 images/sec
current throughput: 700 images/sec
current throughput: 700 images/sec
current throughput: 1550 images/sec
current throughput: 1500 images/sec
current throughput: 1550 images/sec
current throughput: 1450 images/sec
current throughput: 1550 images/sec
current throughput: 1500 images/sec
current throughput: 1500 images/sec
current throughput: 1500 images/sec
current throughput: 1600 images/sec
...

current throughput: 1500 images/sec
current throughput: 1550 images/sec
current throughput: 1500 images/sec
current throughput: 1550 images/sec
current throughput: 1500 images/sec
current throughput: 1600 images/sec
current throughput: 1500 images/sec
current throughput: 1550 images/sec
current throughput: 1550 images/sec
current throughput: 1500 images/sec
current throughput: 1550 images/sec
current throughput: 1500 images/sec
current throughput: 1450 images/sec
current throughput: 1550 images/sec
current throughput: 1600 images/sec
current throughput: 1600 images/sec
current throughput: 1200 images/sec
current throughput: 500 images/sec
current throughput: 50 images/sec

real    1m1.801s
user    1m43.228s
sys     0m6.840s
```

NOTE: If you see lower throughput, please make sure that the Inf1 instance is inf1.2xlarge.

**3.6** While this is running you can see utilization using neuron-top tool in a separate terminal (it takes about a minute to load; also running neuron-top will lower the throughput to around 1200 images/sec):
```bash
/opt/aws/neuron/bin/neuron-top
```

**Note: Please go back to home directory /home/ubuntu**

```bash
cd ~/
```

[Go To Lab 4](4.%20Profiling%20and%20Debugging.md)
